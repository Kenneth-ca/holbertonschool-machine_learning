# 0x11. Attention

## Learning Objectives

### General
* What is the attention mechanism?
* How to apply attention to RNNs
* What is a transformer?
* How to create an encoder-decoder transformer model
* What is GPT?
* What is BERT?
* What is self-supervised learning?
* How to use BERT for specific NLP tasks
* What is SQuAD? GLUE?
